{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <td>All code is written by Joo Won Park, Columbia University (jp3378@columbia.edu)</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import numpy as np\n",
    "import IPython\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.io.wavfile import write\n",
    "from scipy import signal\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the desired audio file (mono) in place of 'drumloop.wav'. The file should be located in\n",
    "the same folder as this python notebook file is. \n",
    "\n",
    "* Load the desired HRTF file from MARL NYU's repository in place of 'S002_marl-nyu.mat'. \n",
    "(which can be found [here](http://steinhardt.nyu.edu/marl/research/head_related_impulse_responses_repository))\n",
    "\n",
    "* Running this code will produce 24 audio files. Each file will be convolved so that that the whole set of file pans the horizontal plane by 15 degrees. The names of file will be 'audioHRIR_0', ...,'audioHRIR_23',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio = 'drumloop.wav'\n",
    "HRIRfile = 'S002_marl-nyu.mat'\n",
    "\n",
    "audiofile = read(Audio)\n",
    "audio_data, audio_f = audiofile[1], audiofile[0]\n",
    "\n",
    "loadedfile = sio.loadmat(HRIRfile)\n",
    "evlist = loadedfile['data']['elevation']\n",
    "azlist = loadedfile['data']['azimuth']\n",
    "impulses = loadedfile['data']['IR'][0]\n",
    "\n",
    "ev0 = np.where(evlist==[[0]]) #index where 0 elevation \n",
    "azonly = azlist[ev0]\n",
    "impulses0 = impulses[ev0[1]]\n",
    "\n",
    "\n",
    "\n",
    "d={}\n",
    "for i in xrange(0,len(azonly)):\n",
    "    d[\"new_{0}\".format(i)]=np.vstack((signal.convolve(audio_data,impulses0[i][:,0],mode='same'),\n",
    "                                      signal.convolve(audio_data,impulses0[i][:,1],mode='same')))\n",
    "\n",
    "\n",
    "def scaleandwrite(outputfile, samplerate, drumdata):\n",
    "    scaled = np.int16((drumdata)/np.max(np.abs(drumdata)) * 32767)\n",
    "    write(outputfile,rate = samplerate, data = scaled.T)\n",
    "\n",
    "    \n",
    "for i in xrange(0,len(azonly)):\n",
    "    scaleandwrite('audioHRIR_{0}.wav'.format(i), drum_f, d['new_{0}'.format(i)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
